{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA - NulovÃ© hodnoty a odlehlÃ¡ pozorovÃ¡nÃ­"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dnes se spoleÄnÄ› podÃ­vÃ¡me, jak to vypadÃ¡, kdyÅ¾ data nejsou tak ÃºplnÄ› v poÅ™Ã¡dku. K analÃ½ze pouÅ¾ijeme data o filmech z let 2016 aÅ¾ 2018 a jejich hodnocenÃ­ z [Internet movie database](https://www.imdb.com/).\n",
    "\n",
    "> V datech mÃ¡me opÄ›t nÃ¡hodnÄ› upravenÃ© nÄ›kterÃ© hodnoty, aby pÅ™Ã­klady hezky vychÃ¡zely.\n",
    "\n",
    "Data jsou k dispozici v nÃ¡sledujÃ­cÃ­ch souborech:\n",
    "* [movies_2016.tsv](static/movies_2016.tsv)\n",
    "* [movies_2017.tsv](static/movies_2017.tsv)\n",
    "* [movies_2018.tsv](static/movies_2018.tsv)\n",
    "* [ratings.tsv](static/ratings.tsv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaÄtenÃ­, kontrola a pÅ™Ã­prava dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data jsou distribuovÃ¡na ve vice souborech a tak je budeme muset naÄÃ­st samostatnÄ› a pak z nich vytvoÅ™it jednu datovou sadu k dalÅ¡Ã­mu zpracovÃ¡nÃ­. To se stÃ¡vÃ¡ nejÄastÄ›ji u historickÃ½ch dat, kterÃ½ch mÅ¯Å¾e bÃ½t velkÃ© mnoÅ¾stvÃ­ a Äasto by bylo zbyteÄnÃ© stahovat celou historii. V tÃ©to podobÄ› si mÅ¯Å¾e analytik vybrat ÄasovÃ© obdobÃ­, kterÃ© ho zajÃ­mÃ¡ nebo jen ÄÃ¡st dat, kterou potÅ™ebuje.\n",
    "\n",
    "ZaÄneme daty o filmech z roku 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 7, saw 5\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-de331fdcf179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmovies_2016\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"static/movies_2016.tsv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmovies_2016\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/data_analysis/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/data_analysis/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/data_analysis/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/data_analysis/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2058\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2059\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2060\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2061\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 7, saw 5\n"
     ]
    }
   ],
   "source": [
    "movies_2016 = pd.read_csv(\"static/movies_2016.tsv\")\n",
    "movies_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Koncovka `tsv` naznaÄuje, Å¾e budeme potÅ™ebovat jinÃ½ zpÅ¯sob naÄtenÃ­. ZatÃ­mco u CSV je oddÄ›lovaÄem hodnot ÄÃ¡rka, TSV pouÅ¾Ã­vÃ¡ tabulÃ¡tor. Je to naÅ¡tÄ›stÃ­ takÃ© znÃ¡mÃ½ formÃ¡t a tak jej umÃ­ pandas snadno zpracovat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_2016 = pd.read_table(\"static/movies_2016.tsv\")\n",
    "movies_2016"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "StejnÃ½m zpÅ¯sobem si naÄteme i dalÅ¡Ã­ soubory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_2017 = pd.read_table(\"static/movies_2017.tsv\")\n",
    "movies_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_2018 = pd.read_table(\"static/movies_2018.tsv\")\n",
    "movies_2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V poslednÃ­ tabulce se nachÃ¡zÃ­ hodnocenÃ­ filmÅ¯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = pd.read_table(\"static/ratings.tsv\")\n",
    "ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SpojenÃ­ v jednu datovou sadu (do dÃ©lky)\n",
    "\n",
    "Nejprve budeme potÅ™ebovat spojit primÃ¡rnÃ­ data o filmech do jednÃ© datovÃ© sady. NaÅ¡tÄ›stÃ­ pro nÃ¡s majÃ­ vÅ¡echny zdroje stejnÃ© sloupce, coÅ¾ takÃ© nebÃ½vÃ¡ pravidlem, pÅ™edevÅ¡Ã­m kdyÅ¾ se v Äase mÄ›nÃ­ zpÅ¯sob zpracovÃ¡nÃ­ a publikace dat.\n",
    "\n",
    "NÃ¡Å¡ pÅ™Ã­klad je vÅ¡ak jednoduchÃ½ a tak i spojenÃ­ vÃ­ce zdrojÅ¯ do jednoho nevyÅ¾aduje Å¾Ã¡dnÃ© mezikroky."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.concat((movies_2016, movies_2017, movies_2018))\n",
    "movies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`concat` umoÅ¾Åˆuje provÃ¡dÄ›t i sloÅ¾itÄ›jÅ¡Ã­ magii a spojovat rÅ¯znÃ© zdroje do jednÃ© datovÃ© sady na zÃ¡kladÄ› rÅ¯znÃ½ch kritÃ©riÃ­. SloÅ¾itost je nejÄastÄ›ji zÃ¡vislÃ¡ na spoleÄnÃ½ch prvcÃ­ch jednotlivÃ½ch zdrojÅ¯, jako jsou indexy Äi nÃ¡zvy sloupcÅ¯. V zÃ¡kladnÃ­m nastavenÃ­ spojuje zdroje do dÃ©lky a protoÅ¾e nÃ¡Å¡ index je automatickÃ½ a nemÃ¡ pro nÃ¡s vÃ½znam, je ignorovÃ¡n a ve vÃ½sledku pÅ™epoÄÃ­tÃ¡n.\n",
    "\n",
    "### SpojenÃ­ v jednu datovou sadu (do Å¡Ã­Å™ky)\n",
    "\n",
    "NadeÅ¡el Äas k existujÃ­cÃ­ datovÃ© sadÄ› pÅ™ipojit informace o hodnocenÃ­ jednotlivÃ½ch filmÅ¯. KaÅ¾dÃ½ film mÃ¡ jednoznaÄnÃ½ identifikÃ¡tor ve sloupci tconst, kterÃ½ je obsaÅ¾en i v datech o hodnocenÃ­, takÅ¾e bude snadnÃ© identifikovat, kterÃ© hodnocenÃ­ patÅ™Ã­ ke kterÃ©mu filmu. Je tu ovÅ¡em jedna potÃ­Å¾, na kterÃ© zÃ¡visÃ­ naÅ¡e dalÅ¡Ã­ poÄÃ­nÃ¡nÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ZatÃ­mco hlavnÃ­ sada obsahuje zÃ¡kladnÃ­ informace o vÃ­ce neÅ¾ 50 000 filmech, informaci o hodnocenÃ­ mÃ¡me jen pro cca 26 000 z nich. TeÄ se musÃ­me rozhodnout pro jednu ze ÄtyÅ™ moÅ¾nÃ½ch strategiÃ­ spojovÃ¡nÃ­, kterÃ¡ ovlivnÃ­ vÃ½sledek. Kdo nÄ›kdy spojoval tabulky v SQL dotazech, bude mÃ­t hned jasno.\n",
    "\n",
    "#### Inner\n",
    "\n",
    "Inner vloÅ¾Ã­ do vÃ½sledku jen ty Å™Ã¡dky, kterÃ© majÃ­ zastoupenÃ­ v obou zdrojovÃ½ch tabulkÃ¡ch. V naÅ¡em pÅ™Ã­padÄ› to znamenÃ¡, Å¾e by ve vÃ½sledku byly jen ty filmy, pro kterÃ© existuje hodnocenÃ­. Jinak Å™eÄeno se nad sloupcem pro identifikaci Å™Ã¡dkÅ¯, kterÃ© k sobÄ› patÅ™Ã­, provede prÅ¯nik a teprve pak dojde ke spojenÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(movies, ratings, how=\"inner\", left_on=\"tconst\", right_on=\"tconst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parametry `left_on` a `right_on` Å™Ã­kÃ¡me, kterÃ© sloupce slouÅ¾Ã­ pro identifikaci k sobÄ› patÅ™Ã­cÃ­ch zÃ¡znamÅ¯ v *levÃ©* a *pravÃ©* tabulce. PouÅ¾Ã­t pro to lze samozÅ™ejmÄ› i index v kterÃ©koli z nich.\n",
    "\n",
    "Na mnoÅ¾stvÃ­ zÃ¡znamÅ¯ ve vÃ½sledku je vidÄ›t, Å¾e touto strategiÃ­ spojenÃ­ jsme pÅ™iÅ¡li o nÄ›kolik hodnocenÃ­, ke kterÃ½m se nepodaÅ™ilo najÃ­t film, a spoustu filmÅ¯, pro kterÃ© se nepodaÅ™ilo najÃ­t hodnocenÃ­.\n",
    "\n",
    "#### Outer\n",
    "\n",
    "Outer zpÅ¯sobÃ­, Å¾e se zdroje spojÃ­ dohromady v plnÃ© velikosti, protoÅ¾e se nad sloupcem pro identifikaci provede nejdÅ™Ã­ve sjednocenÃ­. Pokud jedna z tabulek nebude mÃ­t ve druhÃ© Å™Ã¡dek, se kterÃ½m se bude moci spojit, budou hodnoty nahrazeny nulovÃ½mi hodnotami."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(movies, ratings, how=\"outer\", left_on=\"tconst\", right_on=\"tconst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V tomto pÅ™Ã­padÄ› nepÅ™ijdeme o Å¾Ã¡dnÃ© informace o filmech, ale u spousty z nich nebudeme mÃ­t informaci o hodnocenÃ­ a u nÄ›kolika hodnocenÃ­ zase budou chybÄ›t zÃ¡kladnÃ­ informace o filmech.\n",
    "\n",
    "#### Left a Right\n",
    "\n",
    "Strategie left a right berou jako zÃ¡klad pro spojenÃ­ levou/pravou tabulku, kterÃ¡ tedy zÅ¯stane v pÅ¯vodnÃ­ podobÄ›. DruhÃ¡ tabulka do dvojice se pouÅ¾ije jen pro doplnÄ›nÃ­ informacÃ­ tam, kde je to moÅ¾nÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(movies, ratings, how=\"left\", left_on=\"tconst\", right_on=\"tconst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tady mÃ¡me k dispozici vÅ¡echny filmy a doplnÄ›nÃ© hodnocenÃ­ tam, kde to bylo moÅ¾nÃ©."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(movies, ratings, how=\"right\", left_on=\"tconst\", right_on=\"tconst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tady mÃ¡me naopak vÅ¡echna hodnocenÃ­ a informace o filmu jen tam, kde je bylo moÅ¾nÃ© dohledat.\n",
    "\n",
    "FinÃ¡lnÃ­ strategie vÅ¾dy zÃ¡leÅ¾Ã­ na tom, kterÃ¡ data potÅ™ebujeme a kterÃ¡ si mÅ¯Å¾eme dovolit vypustit. VÃ­ce si toto rozebereme v dalÅ¡Ã­ch kapitolÃ¡ch. Pro tuto chvÃ­li pro nÃ¡s budou dÅ¯leÅ¾itÄ›jÅ¡Ã­ informace o filmech a tak zÅ¯staneme u strategie, kterÃ¡ pouÅ¾ije filmy jako zÃ¡klad pro spojenÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(movies, ratings, how=\"left\", left_on=\"tconst\", right_on=\"tconst\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NulovÃ© hodnoty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NulovÃ© (neboli chybÄ›jÃ­cÃ­) hodnoty jsou snadno identifikovatelnÃ© a znamenajÃ­ v podstatÄ› chybÄ›jÃ­cÃ­ data v datasetu. NejÄastÄ›ji jsou oznaÄeny jako `NaN`, coÅ¾ je ekvivalent pythonÃ­ho `None` a mÅ¯Å¾e bÃ½t pouÅ¾it i pÅ™Ã­mo z knihovny numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas identifikuje chybÄ›jÃ­cÃ­ hodnoty automaticky, pokud je buÅˆka ve zdrojovÃ©m souboru zcela prÃ¡zdnÃ¡. Pokud zdrojovÃ¡ data obsahujÃ­ nÄ›jakou jinou reprezentaci (napÅ™.: `N/A`, `\\\\N` a podobnÄ›). je potÅ™eba je na `np.nan` nejdÅ™Ã­ve pÅ™evÃ©zt. Po pÅ™evodu se nÃ¡m bude s daty mnohem lÃ©pe pracovat.\n",
    "\n",
    "Informace o chybÄ›jÃ­cÃ­ch hodnotÃ¡ch lze vyÄÃ­st z informacÃ­ o datech, deskriptivnÃ­ch statistikÃ¡ch a pak takÃ© pÅ™Ã­mo jejich souÄtem napÅ™Ã­Ä daty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoslednÃ­ moÅ¾nost je sice nejdelÅ¡Ã­ na psanÃ­, ale vÃ½sledek je nejlÃ©pe vidÄ›t a nevyÅ¾aduje odeÄÃ­tÃ¡nÃ­ od celkovÃ©ho poÄtu zÃ¡znamÅ¯."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro prÃ¡ci s nulovÃ½mi hodnotami neexistuje jedna sprÃ¡vnÃ¡ a univerzÃ¡lnÃ­ cesta. V podstatÄ› si musÃ­me velmi uvÃ¡Å¾enÄ› vybrat z jednÃ© ze dvou moÅ¾nostÃ­:\n",
    "\n",
    "1. MazÃ¡nÃ­\n",
    "2. DoplnÄ›nÃ­\n",
    "\n",
    "### MazÃ¡nÃ­\n",
    "\n",
    "MazÃ¡nÃ­ je velmi jednoduchÃ©. Smazat mÅ¯Å¾eme celÃ© sloupce nebo Å™Ã¡dky, ale pÅ™ijdeme tÃ­m i o potencionÃ¡lnÄ› uÅ¾iteÄnÃ¡ data a snÃ­Å¾Ã­me tÃ­m jejich reprezentativnost.\n",
    "\n",
    "V naÅ¡em pÅ™Ã­padÄ› mÅ¯Å¾eme smazat sloupec endYear, kterÃ½ neobsahuje ani jednu hodnotu a tak jeho smazÃ¡nÃ­m o nic nepÅ™ijdeme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"endYear\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pro mazÃ¡nÃ­ souvisejÃ­cÃ­ pÅ™Ã­mo s chybÄ›jÃ­cÃ­mi hodnotami mÃ¡me k dispozici metodu `dropna`, kterÃ¡ umÃ­ mazat Å™Ã¡dky Äi sloupce obsahujÃ­cÃ­ alespoÅˆ jednu chybÄ›jÃ­cÃ­ hodnotu nebo zcela naplnÄ›nÃ© chybÄ›jÃ­cÃ­mi hodnotami. Nic dalÅ¡Ã­ho mazat nebudeme, ale vÃ½sledek jednotlivÃ½ch strategiÃ­ si pÅ™es to ukÃ¡Å¾eme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AktuÃ¡lnÄ› mÃ¡me v datech 53096 zÃ¡znamÅ¯. Takto by to vypadalo, pokud bychom nechali smazat vÅ¡echny Å™Ã¡dky, kterÃ© obsahujÃ­ alespoÅˆ jednu chybÄ›jÃ­cÃ­ hodnotu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how=\"any\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A takto, pokud bychom smazali Å™Ã¡dky, kterÃ© majÃ­ pouze chybÄ›jÃ­cÃ­ hodnoty:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z poÄtu zbylÃ½ch Å™Ã¡dkÅ¯ je jasnÃ©, Å¾e se Å¾Ã¡dnÃ½ nesmazal a kaÅ¾dÃ½ Å™Ã¡dek tedy obsahuje alespoÅˆ nÄ›jakou hodnotu.\n",
    "\n",
    "MazÃ¡nÃ­ by mohlo zpÅ¯sobit ztrÃ¡tu potencionÃ¡lnÄ› uÅ¾iteÄnÃ½ch dat. SmazÃ¡nÃ­m filmÅ¯ bez hodnocenÃ­ bychom pÅ™iÅ¡li o polovinu filmÅ¯, coÅ¾ by pro analÃ½zu nÄ›kterÃ½ch jejich vlastnostÃ­ mohlo bÃ½t neÅ¾Ã¡doucÃ­.\n",
    "\n",
    "### DoplnÄ›nÃ­\n",
    "\n",
    "Bez mazÃ¡nÃ­ musÃ­me v dalÅ¡Ã­ch krocÃ­ch buÄ poÄÃ­tat s tÃ­m, Å¾e mÃ¡me v datech chybÄ›jÃ­cÃ­ hodnoty, nebo je do dat nÄ›jak doplnit.\n",
    "\n",
    "Doplnit data lze mnoha zpÅ¯soby a zÃ¡leÅ¾Ã­ hlavnÄ› na promÄ›nnÃ©, kterou budeme doplÅˆovat. Je tÅ™eba mÃ­t takÃ© na pamÄ›ti, Å¾e doplnÄ›nÃ¡ data nejsou reÃ¡lnÃ¡ a mÄ›la by plnit jen pomocnou funkci. MoÅ¾nosti jsou nÃ¡sledujÃ­cÃ­:\n",
    "\n",
    "* Nahradit chybÄ›jÃ­cÃ­ hodnoty prÅ¯mÄ›rem, mediÃ¡nem Äi nejÄastÄ›ji se vyskytujÃ­cÃ­ hodnotou. DopoÄtenÃ¡ hodnota pÅ™itom mÅ¯Å¾e vychÃ¡zet z celÃ©ho zbytku datasetu nebo jen nÄ›kolika Å™Ã¡dkÅ¯ okolo chybÄ›jÃ­cÃ­ hodnoty (KNN - K Nearest Neighbors).\n",
    "* Pokud se jednÃ¡ o data sbÃ­ranÃ¡ v Äase, mÅ¯Å¾eme chybÄ›jÃ­cÃ­ hodnotu nahradit poslednÃ­ hodnotou namÄ›Å™enou pÅ™ed tou chybÄ›jÃ­cÃ­ nebo tou prvnÃ­ nÃ¡sledujÃ­cÃ­ po chybÄ›jÃ­cÃ­ hodnotÄ›.\n",
    "* Pokud je v datech viditelnÃ½ trend, mÅ¯Å¾eme zkusit chybÄ›jÃ­cÃ­ data dopoÄÃ­tat napÅ™. pomocÃ­ lineÃ¡rnÃ­ regrese, o kterÃ© si budeme povÃ­dat v lekcÃ­ch o machine learningu.\n",
    "\n",
    "U vÃ­ce neÅ¾ 12 000 filmÅ¯ nÃ¡m chybÃ­ informace o jejich stopÃ¡Å¾i. PojÄme zkusit najÃ­t nejvhodnÄ›jÅ¡Ã­ cestu k doplnÄ›nÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.runtimeMinutes.hist(bins=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram trpÃ­ tÃ­m, Å¾e v datech mÃ¡me i film dlouhÃ½ 36 hodin. Jak na to zareagujÃ­ popisnÃ© statistiky?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.runtimeMinutes.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "75 % filmÅ¯ je kratÅ¡Ã­ch neÅ¾ 100 minut a mediÃ¡n s prÅ¯mÄ›rem pÅ™Ã­liÅ¡ nereflektujÃ­ extrÃ©mnÃ­ hodnoty, takÅ¾e bychom jednu z tÄ›chto hodnot mohli pouÅ¾Ã­t. Pro Ãºplnost se jeÅ¡tÄ› podÃ­vÃ¡me, kterÃ¡ hodnota se vyskytuje v datech ÃºplnÄ› nejÄastÄ›ji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.runtimeMinutes.mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.runtimeMinutes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vzhledem k malÃ½m rozdÃ­lÅ¯m moc nesejde na tom, zda pouÅ¾ijeme mean, mediÃ¡n nebo mode. Zkusme tedy mediÃ¡n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.runtimeMinutes = data.runtimeMinutes.fillna(data.runtimeMinutes.median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NovÃ½ sloupec s doplnÄ›nÃ½mi chybÄ›jÃ­cÃ­mi hodnotami uloÅ¾Ã­me zpÄ›t do pÅ¯vodnÃ­ch dat a mÃ¡me hotovo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U kategoriÃ¡lnÃ­ promÄ›nnÃ© genres nemÃ¡me tolik moÅ¾nostÃ­ jako u numerickÃ½ch promÄ›nnÃ½ch a navÃ­c tento sloupec obsahuje rÅ¯znÃ© kombinace Å¾Ã¡nrÅ¯. V neposlednÃ­ Å™adÄ› se s chybÄ›jÃ­cÃ­mi hodnotami nepracuje u textovÃ½ch sloupcÅ¯ tak snadno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.genres.value_counts()[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data obsahujÃ­ celkem 814 unikÃ¡tnÃ­ch kombinacÃ­ Å¾Ã¡nrÅ¯ a vÃ­ce neÅ¾ tÅ™etina filmÅ¯ jsou dokumenty. Doplnit takovou promÄ›nnou o nejÄastÄ›jÅ¡Ã­ hodnotu by asi nebyl nejlepÅ¡Ã­ nÃ¡pad a tak budeme pÅ™edpoklÃ¡dat, Å¾e chybÄ›jÃ­cÃ­ hodnota znamenÃ¡, Å¾e se film zkrÃ¡tka nepodaÅ™ilo zaÅ™adit do Å¾Ã¡dnÃ© z pÅ™ipravenÃ½ch Å¡katulek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.genres.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data.genres.isnull()) & (data.averageRating.isnull())].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NavÃ­c je vidÄ›t, Å¾e jen okolo 200 filmÅ¯ z tÄ›ch s chybÄ›jÃ­cÃ­m Å¾Ã¡nrem mÃ¡ nÄ›jakÃ© hodnocenÃ­, coÅ¾ podporuje pocit, Å¾e se nejednÃ¡ o bÄ›Å¾nÃ© snÃ­mky. NicmÃ©nÄ› je to stÃ¡le jen pocit.\n",
    "\n",
    "ChybÄ›jÃ­cÃ­ hodnoty ve sloupci s originÃ¡lnÃ­m nÃ¡zvem nepÅ¯jde doplnit tak snadno a doplÅˆovat hodnocenÃ­ filmÅ¯ jakÃ½mkoli zpÅ¯sobem takÃ© nenÃ­ dobrÃ½ nÃ¡pad, protoÅ¾e by to mohlo ovlivnit vÃ½sledky pÅ™Ã­padnÃ© navazujÃ­cÃ­ analÃ½zy.\n",
    "\n",
    "Jak vidno, mazÃ¡nÃ­ Äi doplnÄ›nÃ­ hodnot je vÅ¾dy rizikovÃ© a takovÃ©mu kroku by mÄ›lo pÅ™edchÃ¡zet dobrÃ© zvÃ¡Å¾enÃ­ a zdÅ¯vodnÄ›nÃ­. Je takÃ© vÃ­ce neÅ¾ rozumnÃ© si na konci analÃ½z sesumÃ­rovat svÃ© vÃ½sledky a zkusit odhadnout, jakÃ½ vliv na nÄ› mohla mÃ­t strategie naklÃ¡dÃ¡nÃ­ s chybÄ›jÃ­cÃ­mi hodnotami."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OdlehlÃ¡ mÄ›Å™enÃ­\n",
    "\n",
    "ChybÄ›jÃ­cÃ­ hodnoty na nÃ¡s v ideÃ¡lnÃ­m pÅ™Ã­padÄ› vyskoÄÃ­ hned po naÄtenÃ­ dat, pÅ™Ã­padnÄ› je objevÃ­me zÃ¡hy pÅ™i pohledu na jednotlivÃ© promÄ›nnÃ©. S odlehlÃ½mi mÄ›Å™enÃ­mi je to sloÅ¾itÄ›jÅ¡Ã­, protoÅ¾e na nÄ› v tom nejhorÅ¡Ã­m pÅ™Ã­padÄ› nemusÃ­me narazit vÅ¯bec a jejich vÃ½skyt ovlivnÃ­ vÃ½sledky naÅ¡Ã­ analÃ½zy.\n",
    "\n",
    "Å½e nÃ¡m nÄ›jakÃ¡ hodnota jeÅ¡tÄ› nesedÃ­ do zbytku dat, jeÅ¡tÄ› nemusÃ­ nic zÃ¡sadnÃ­ho znamenat a hlavnÄ› nemusÃ­ jÃ­t vÅ¾dy o chybu. StejnÄ› jako v pÅ™Ã­padÄ› chybÄ›jÃ­cÃ­ch hodnot je i zde pÅ™ed opravou Äi jinÃ½m zÃ¡sahem tÅ™eba dobÅ™e zvÃ¡Å¾it jeho nÃ¡sledky. NejÄastÄ›jÅ¡Ã­ pÅ™Ã­Äiny vÃ½skytu odlehlÃ½ch mÄ›Å™enÃ­ jsou:\n",
    "\n",
    "* LidskÃ¡ chyba (napÅ™. pÅ™i zÃ¡pisu dat v dotaznÃ­ku)\n",
    "* Chyba mÄ›Å™enÃ­ (napÅ™. zÃ¡vada na mÄ›Å™Ã­cÃ­m pÅ™Ã­stroji)\n",
    "* Chyba pÅ™i manipulace s daty, agregaci, zpracovÃ¡nÃ­\n",
    "* ValidnÃ­ leÄ extrÃ©mnÃ­ hodnota\n",
    "\n",
    "PÅ™i hledÃ¡nÃ­ odlehlÃ½ch mÄ›Å™enÃ­ se nejdÅ™Ã­ve zamÄ›Å™Ã­me na jednotlivÃ© promÄ›nnÃ© a pak na jejich kombinace. ZÃ¡kladnÃ­ pÅ™ehled a pÅ™edstavu o tom, co mÅ¯Å¾eme dÃ¡le oÄekÃ¡vat nÃ¡m poskytne znÃ¡my krabicovÃ½ graf. PouÅ¾Ã­t jej budeme muset pro kaÅ¾dou promÄ›nnou zvlÃ¡Å¡Å¥, protoÅ¾e jednotlivÃ© promÄ›nnÃ© majÃ­ velmi rozdÃ­lnÃ½ rozsah hodnot.\n",
    "\n",
    "### IRQ\n",
    "\n",
    "PrvnÃ­ metodou pro detekci odlehlÃ½ch mÄ›Å™enÃ­ je inter-quartile range, kterÃ½ jsme si popsali pÅ™i analÃ½ze jednÃ© promÄ›nnÃ© u popisu krabicovÃ©ho grafu. Pro zopakovÃ¡nÃ­: vezme se rozsah mezi prvnÃ­m a tÅ™etÃ­m quartilem a vynÃ¡sobÃ­ se 1,5Ã—. TÃ­m se vytvoÅ™Ã­ hornÃ­ a spodnÃ­ hranice (vodorovnÃ© ÄÃ¡rky v grafu) a co se mezi nÄ› nevejde, je oznaÄeno jako odlehlÃ© mÄ›Å™enÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.runtimeMinutes.plot.box(figsize=(10,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S daty uÅ¾ umÃ­me lÃ©pe pracovat, takÅ¾e si mÅ¯Å¾eme zkusit vypoÄÃ­tat tuto metodu i ruÄnÄ›."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = data.runtimeMinutes.quantile(0.25)\n",
    "q3 = data.runtimeMinutes.quantile(0.75)\n",
    "irq = q3 - q1\n",
    "dolni_hranice = q1-1.5*irq\n",
    "horni_hranice = q3+1.5*irq\n",
    "print(f\"Q1: {q1}, Q3: {q3}, IRQ: {irq}, dolnÃ­ hranice: {dolni_hranice}, hornÃ­ hranice: {horni_hranice}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VypoÄtenÃ© hranice nÃ¡m poslouÅ¾Ã­ pro manuÃ¡lnÃ­ filtraci dat, takÅ¾e uvidÃ­me i v tabulce to, co je vidÄ›t v grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.runtimeMinutes < dolni_hranice]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.runtimeMinutes > horni_hranice]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skoro 7 tisÃ­c filmÅ¯ je z pohledu svÃ© stopÃ¡Å¾e oznaÄeno jako odlehlÃ¡ mÄ›Å™enÃ­. VÃ½poÄet pomocÃ­ IRQ nabÃ­zÃ­ jednoduchou cestu k vÃ½sledkÅ¯m, ale nenÃ­ jednoduÅ¡e moÅ¾nÃ© si rozsah hodnot upravit podle svÃ½ch pÅ™edstav. To je moÅ¾nÃ© v druhÃ© populÃ¡rnÃ­ metodÄ› detekce odlehlÃ½ch mÄ›Å™enÃ­ - Z score.\n",
    "\n",
    "### Z score\n",
    "\n",
    "z score je metoda detekce odlehlÃ½ch mÄ›Å™enÃ­ definovanÃ¡ jednoduchÃ½m vzorcem a zÃ¡vislÃ¡ na smÄ›rodatnÃ© odchylce. PrÃ¡vÄ› dÃ­ky jednoduchÃ©mu vzoreÄku a nastavitelnÃ© hranici je moÅ¾nÃ© si urÄit, co pro nÃ¡s znamenÃ¡ odlehlÃ© mÄ›Å™enÃ­. Vzorec vypadÃ¡ nÃ¡sledovnÄ›:\n",
    "\n",
    "$$ z = \\frac{x - \\mu}{\\sigma} $$\n",
    "\n",
    "`x` oznaÄuje konkrÃ©tnÃ­ hodnotu promÄ›nnÃ©, `ğœ‡` oznaÄuje prÅ¯mÄ›r pro danou promÄ›nnou a `ğœ` smÄ›rodatnou odchylku. Z score uvÃ¡dÃ­, kolik nÃ¡sobkÅ¯ smÄ›rodatnÃ© odchylky je danÃ¡ hodnota vzdÃ¡lenÃ¡ od prÅ¯mÄ›ru. ÄŒÃ­m blÃ­Å¾e bude zkoumanÃ¡ hodnota prÅ¯mÄ›ru, tÃ­m blÃ­Å¾e bude Z score nule. VÃ½hodou je, Å¾e si pro Z score mÅ¯Å¾eme sami urÄit hranice pro detekci odlehlÃ½ch mÄ›Å™enÃ­ a takÃ© to, Å¾e dÃ­ky nÃ¡sobkÅ¯m smÄ›rodatnÃ© odchylky, ve kterÃ½ch se tato hranice stanovuje, vÃ­me, kolik procent zÃ¡znamÅ¯ mÃ¡me pokryto. O smÄ›rodatnÃ© odchylce a normÃ¡lnÃ­m rozloÅ¾enÃ­ si budeme jeÅ¡tÄ› povÃ­dat v lekci o reprezentativnosti dat.\n",
    "\n",
    "> U promÄ›nnÃ© s normÃ¡lnÃ­m rozloÅ¾enÃ­m, kde je nejvÃ­ce vÃ½skytÅ¯ kolem prÅ¯mÄ›ru a rostoucÃ­ vzdÃ¡lenostÃ­ od prÅ¯mÄ›ru klesÃ¡ poÄet vÃ½skytÅ¯ to funguje tak, Å¾e do vzdÃ¡lenosti jednÃ© smÄ›rodatnÃ© odchylky se vyskytuje 68 % vÅ¡ech hodnot, dvojnÃ¡sobek smÄ›rodatnÃ© odchylky pak pokrÃ½vÃ¡ 95 % vÅ¡ech hodnot a trojnÃ¡sobek 99 %.\n",
    "\n",
    "Je Äas to vyzkouÅ¡et:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(20 - data.runtimeMinutes.mean()) / data.runtimeMinutes.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(2 - data.runtimeMinutes.mean()) / data.runtimeMinutes.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DvacetiminutovÃ½ film je od prÅ¯mÄ›rnÃ© hodnoty vzdÃ¡len pÅ™ibliÅ¾nÄ› dvojnÃ¡sobek smÄ›rodatnÃ© odchylky. StriktnÄ› vzato by se nezaÅ™adil mezi 95 % nejÄastÄ›jÅ¡Ã­ch hodnot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs(180 - data.runtimeMinutes.mean()) / data.runtimeMinutes.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TÅ™i hodiny trvajÃ­cÃ­ film je od prÅ¯mÄ›ru vzdÃ¡len jeÅ¡tÄ› o nÄ›co vÃ­ce to skoro o trojnÃ¡sobek smÄ›rodatnÃ© odchylky.\n",
    "\n",
    "Z score vypoÄtenÃ© pro vÅ¡echny zÃ¡znamy nÃ¡m mÅ¯Å¾e takÃ© poslouÅ¾it pro filtraci dat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zs = abs((data.runtimeMinutes - data.runtimeMinutes.mean()) / data.runtimeMinutes.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[zs > 3].sort_values(by=\"runtimeMinutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Z score nÃ¡m na spodnÃ­ hranici nedetekovalo Å¾Ã¡dnÃ¡ odlehlÃ¡ mÄ›Å™enÃ­ a na tÃ© hornÃ­ pak 180 filmÅ¯ delÅ¡Ã­ch neÅ¾ tÅ™i hodiny.\n",
    "\n",
    "### VÃ­ce promÄ›nnÃ½ch najednou\n",
    "\n",
    "Pro kompletnÃ­ detekci odlehlÃ½ch mÄ›Å™enÃ­ je jeÅ¡tÄ› potÅ™eba se na data podÃ­vat z pohledu vÃ­ce dimenzÃ­. Kombinace vÃ­ce vlastnostÃ­ totiÅ¾ mÅ¯Å¾e bÃ½t zcela mimo oÄekÃ¡vanou hodnotu, i kdyÅ¾ kaÅ¾dÃ¡ z vlastnostÃ­ samostatnÄ› vÅ¯bec nemusÃ­ vyboÄovat z Å™ady.\n",
    "\n",
    "Pro detekci takovÃ½ch pÅ™Ã­padÅ¯ pouÅ¾ijeme stejnÄ› jako pro hledÃ¡nÃ­ trendÅ¯ a korelacÃ­ scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "scatter_matrix(data, figsize=(20, 20));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ve scatter plotech nenÃ­ na prvnÃ­ pohled nic vidÄ›t, resp. jsou zde patrnÃ¡ odlehlÃ¡ mÄ›Å™enÃ­, kterÃ¡ jsme jiÅ¾ detekovali dÅ™Ã­ve.\n",
    "\n",
    "Jeden zajÃ­mavÃ½ bod zde ale pÅ™eci jen mÃ¡me. Je vidÄ›t v grafu zÃ¡vislosti celkovÃ© dÃ©lky stopÃ¡Å¾e a poÄtu hodnocenÃ­."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.scatter(x=\"runtimeMinutes\", y=\"numVotes\", grid=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Å½e se v poÄtu hlasovÃ¡nÃ­ objevÃ­ extrÃ©mnÄ› Äasto hodnocenÃ© filmy, to je oÄekÃ¡vanÃ© a vÃ­me to z pÅ™edchozÃ­ch krokÅ¯ analÃ½zy. StejnÃ¡ je situace u extrÃ©mnÃ­ch hodnot dÃ©lky filmÅ¯, kde se nÄ›jakÃ© extrÃ©my na obÄ› strany dajÃ­ oÄekÃ¡vat. Kombinace obou tÄ›chto vlastnostÃ­ mÃ¡ takÃ© vÃ­ce mÃ©nÄ› oÄekÃ¡vanÃ½ charakter a lidÃ© nejÄastÄ›ji hodnotÃ­ filmy s prÅ¯mÄ›rnou dÃ©lkou. AÅ¾ na jednu vÃ½jimku, jak je patrnÃ© z grafu.\n",
    "\n",
    "I kdyÅ¾ film majÃ­cÃ­ 300 000 hodnocenÃ­ nenÃ­ nijak vÃ½jimeÄnÃ½ a dÃ©lka 400 minut takÃ© nenÃ­ z nejextrÃ©mnÄ›jÅ¡Ã­ch, spoleÄnÃ¡ kombinace tÄ›chto hodnot je pÅ™inejmenÅ¡Ã­m podezÅ™elÃ¡ a zaslouÅ¾ila by si v bÄ›Å¾nÃ© analÃ½ze dalÅ¡Ã­ zkoumÃ¡nÃ­.\n",
    "\n",
    "StejnÄ› jako v pÅ™edchozÃ­ch krocÃ­ch u IRQ a Z score, mÅ¯Å¾eme i zde pouÅ¾Ã­t algoritmy pro detekci konkrÃ©tnÃ­ch odlehlÃ½ch pozorovÃ¡nÃ­ ve dvou a vÃ­ce dimenzÃ­ch. Jejich rozbor a porovnÃ¡nÃ­ je mimo zÃ¡bÄ›r tÃ©to lekce, ale jeden jednoduchÃ½ a celkem populÃ¡rnÃ­ si pÅ™eci jen ukÃ¡Å¾eme.\n",
    "\n",
    "### DBSCAN\n",
    "\n",
    "DBSCAN (Density-Based Spatial Clustering of Applications with Noise) je algoritmus, kterÃ½ dokÃ¡Å¾e shlukovat body v prostoru (o libovolnÃ©m poÄtu dimenzÃ­) k sobÄ› do skupin podle toho, jak moc jsou body blÃ­zko u sebe. JednoduÅ¡e Å™eÄeno prohledÃ¡ okolÃ­ bodÅ¯ v prostoru a pokud najde dostatek sousedÅ¯, pÅ™idÃ¡ je do spoleÄnÃ© skupinky. Pokud ovÅ¡em body nemajÃ­ dostatek sousedÅ¯, jsou oznaÄeny jako Å¡um (noise) a v naÅ¡em pÅ™Ã­padÄ› je lze povaÅ¾ovat za odlehlÃ¡ mÄ›Å™enÃ­, protoÅ¾e se zkrÃ¡tka vyskytujÃ­ pÅ™Ã­liÅ¡ daleko od ostatnÃ­ch a nenÃ­ jich dost, aby si vytvoÅ™ili vlastnÃ­ skupinku.\n",
    "\n",
    "Velikost prohledÃ¡vanÃ©ho okolÃ­ a nezbytnÃ½ poÄet sousedÅ¯ jsou nastavitelnÃ© parametry, takÅ¾e i vÃ½sledky tohoto algoritmu budou stejnÄ› jako u Z score zÃ¡viset na sprÃ¡vnÃ©m nastavenÃ­ a interpretaci. Pro jednoduchost se budeme pohybovat jen v prostoru o dvou dimenzÃ­ch, coÅ¾ nÃ¡m umoÅ¾nÃ­ vÃ½sledky pÄ›knÄ› vizualizovat.\n",
    "\n",
    "CelÃ½ proces bude troÅ¡ku komplikovanÃ½, ale podstatnÃ© pro nÃ¡s je porozumnÄ›t vÅ¡em krokÅ¯m neÅ¾ si hned zapamatovat celÃ½ postup a umÄ›t jej naprogramovat.\n",
    "\n",
    "Nejprve musÃ­me z dat odebrat nulovÃ© hodnoty, protoÅ¾e s tÄ›mi si algoritmy Äasto neumÃ­ poradit. Nechceme pÅ™i tom zasahovat do originÃ¡lnÃ­ch dat, takÅ¾e si vÃ½sledek uloÅ¾Ã­me do novÃ© promÄ›nnÃ©. PÅ™i odstraÅˆovÃ¡nÃ­ chybÄ›jÃ­cÃ­ch dat jsme zvolili strategii `any` takÅ¾e staÄÃ­ jedna nulovÃ¡ hodnota pro odstranÄ›nÃ­ Å™Ã¡dku a `subset` nastavil sloupce, kam se bude pandas dÃ­vat, protoÅ¾e napÅ™. chybÄ›jÃ­cÃ­ hodnota ve sloupci s originÃ¡lnÃ­m nÃ¡zvem nÃ¡s aktuÃ¡lnÄ› nezajÃ­mÃ¡ a nenÃ­ tÅ™eba, aby zpÅ¯sobila odstranÄ›nÃ­ celÃ©ho Å™Ã¡dku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_null_values = data.dropna(how=\"any\", subset=[\"runtimeMinutes\", \"numVotes\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NynÃ­ potÅ™ebujeme upravit Å¡kÃ¡lu naÅ¡ich dat. ProblÃ©m je v tom, Å¾e dÃ©lka filmu v minutÃ¡ch se pohybuje v dost odliÅ¡nÃ½ch cifrÃ¡ch neÅ¾ poÄet hlasujÃ­cÃ­ch, coÅ¾ by nÃ¡m komplikovalo sprÃ¡vnÃ© nastavenÃ­ algoritmu a vÃ½poÄet vzdÃ¡lenosti mezi jednotlivÃ½mi body. VÃ­ce o Å¡kÃ¡lovÃ¡nÃ­ bude Å™eÄ v dalÅ¡Ã­ch lekcÃ­ch, protoÅ¾e je to celkem bÄ›Å¾nÃ¡ souÄÃ¡st pÅ™Ã­pravy dat pro strojovÃ© uÄenÃ­.\n",
    "Å kÃ¡lovÃ¡nÃ­ na menÅ¡Ã­ hodnoty se provede pro oba sloupce najednou, takÅ¾e vztah mezi nimi zÅ¯stane zachovÃ¡n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "transformed = sc.fit_transform(no_null_values[[\"runtimeMinutes\", \"numVotes\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÃ½sledkem je dvourozmÄ›rnÃ¡ matice, kterou si pro ovÄ›Å™enÃ­ mÅ¯Å¾eme takÃ© vizualizovat. PÅ™evodem z pandas `DataFrame` na numpy matici jsme pÅ™iÅ¡li o nÃ¡zvy sloupcÅ¯, ale ke sloupcÅ¯m samotnÃ½m se dokÃ¡Å¾eme dostat dÃ­ky rozÅ¡Ã­Å™enÃ© indexaci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.scatter(x=transformed[:, 0], y=transformed[:, 1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V nÃ¡sledujÃ­cÃ­m kroku si vytvoÅ™Ã­me model, kterÃ½ bude prohledÃ¡vat okolÃ­ o velikosti 4 a za skupinku bude povaÅ¾ovat shluk minimÃ¡lnÄ› dvou bodÅ¯."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "model = DBSCAN(eps=4, min_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NechÃ¡me model nauÄit se naÅ¡e transformovanÃ¡ data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VÃ½sledek obsahuje mimo jinÃ© `labels_`, coÅ¾ je seznam tzv. znaÄek, kterÃ½mi oznaÄil jednotlivÃ© Å™Ã¡dky z naÅ¡ich dat a tÃ­m je zaÅ™adil do skupin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PÅ™evodem na mnoÅ¾inu (`set`) dokÃ¡Å¾eme zjistit, kolik takovÃ½ch skupinek vytvoÅ™il."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(result.labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A teÄ uÅ¾ k vizualizaci. K tomu budeme potÅ™ebovat vykreslit do scatter plotu rÅ¯znÃ© barvy, abychom mezi skupinkami dokÃ¡zali rozliÅ¡it. U takto malÃ©ho poÄtu bychom si dokÃ¡zali barvy urÄit u ruÄnÄ›, ale pomoci nÃ¡m mÅ¯Å¾e barevnÃ¡ mapa, kterÃ¡ hodnoty pro jednotlivÃ© skupiny rozloÅ¾Ã­ na vybranÃ© barevnÃ© Å¡kÃ¡le a my je tÃ­m pÃ¡dem dokÃ¡Å¾eme rozeznat v grafu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "\n",
    "cmap = cm.get_cmap(\"cividis\")\n",
    "\n",
    "no_null_values.plot.scatter(x=\"runtimeMinutes\", y=\"numVotes\", c=result.labels_, cmap=cmap);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Å edÃ¡ barva oznaÄuje skupinku ÄÃ­slo 0, kterÃ¡ obsahuje nejvÃ­ce filmÅ¯. -1 oznaÄuje odlehlÃ¡ mÄ›Å™enÃ­, kterÃ¡ jsou daleko a navÃ­c jich je pÅ™Ã­liÅ¡ mÃ¡lo na vytvoÅ™enÃ­ skupiny. Å½lutÃ¡ je skupinka ÄÃ­slo 1, kterÃ¡ nenÃ­ dost blÃ­zko ostatnÃ­m, ale je dost poÄetnÃ¡ na to, aby si vytvoÅ™ila skupinku vlastnÃ­.\n",
    "\n",
    "Takto mÅ¯Å¾e ve vÃ½sledku vypadat automatickÃ¡ detekce odlehlÃ½ch mÄ›Å™enÃ­ i v mnoha dimenzÃ­ch. Co se ale s odlehlÃ½mi mÄ›Å™enÃ­mi nakonec stane a jak ovlivnÃ­ vÃ½sledek celÃ© analÃ½zy, to uÅ¾ zÃ¡leÅ¾Ã­ jen na analytikovi a zvolenÃ½ch postupech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ZÃ¡vÄ›r\n",
    "\n",
    "DneÅ¡nÃ­ lekce ukÃ¡zala nÄ›kolik zpÅ¯sobÅ¯, jak detekovat a jak se vypoÅ™Ã¡dat s chybÄ›jÃ­cÃ­mi daty a odlehlÃ½mi mÄ›Å™enÃ­mi. FinÃ¡lnÃ­ volba je vÅ¾dy zÃ¡vislÃ¡ na naÅ¡ich cÃ­lech. Jinak se budeme chovat k datÅ¯m pÅ™ipravovanÃ½m pro explorativnÃ­ analÃ½zu a jinak k datÅ¯m pro budoucÃ­ model strojovÃ©ho uÄenÃ­. Je takÃ© tÅ™eba bÃ½t velmi opatrnÃ½ s mazÃ¡nÃ­m potencionÃ¡lnÄ› uÅ¾iteÄnÃ½ch dat Äi kalkulacÃ­ s vymyÅ¡lenÃ½mi daty.\n",
    "\n",
    "## ÄŒas na hranÃ­\n",
    "\n",
    "Pokud mÃ¡Å¡ po minulÃ© lekci hotovou svou vlastnÃ­ analÃ½zu, mÅ¯Å¾eÅ¡ do nÃ­ zkusit pÅ™idat dnes zÃ­skanÃ© znalosti a ovÄ›Å™it, jak se to promÃ­tne do vÃ½sledkÅ¯ a zÃ¡vÄ›rÅ¯."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
